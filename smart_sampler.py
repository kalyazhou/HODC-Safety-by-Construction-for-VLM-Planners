"""
æ™ºèƒ½é‡‡æ ·æ¨¡å— - ä»nuScenes Fullä¸­é‡‡æ ·200ä¸ªä»£è¡¨æ€§åœºæ™¯
ç”¨äºæ‰©å±•å®éªŒï¼šä»10åœºæ™¯(mini) â†’ 200åœºæ™¯(sampled full)
"""

import os
import random
import numpy as np
from nuscenes import NuScenes
from collections import defaultdict


def check_scene_has_images(nusc, scene):
    """æ£€æŸ¥åœºæ™¯çš„å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    try:
        first_sample = nusc.get('sample', scene['first_sample_token'])
        cam_front_token = first_sample['data']['CAM_FRONT']
        cam_front_data = nusc.get('sample_data', cam_front_token)
        image_path = os.path.join(nusc.dataroot, cam_front_data['filename'])
        return os.path.exists(image_path)
    except:
        return False


def analyze_scene_features(nusc, scene):
    """åˆ†æåœºæ™¯ç‰¹å¾ï¼ˆç”¨äºåˆ†ç±»ï¼‰"""
    scene_token = scene['token']
    first_sample = nusc.get('sample', scene['first_sample_token'])
    
    # 1. æ—¶é—´ç‰¹å¾ï¼ˆç™½å¤©/å¤œé—´ï¼‰
    timestamp = first_sample['timestamp']
    hour = (timestamp // 1000000) % 86400 // 3600  # ç®€åŒ–ç‰ˆæœ¬
    is_night = (hour < 6 or hour > 20)
    
    # 2. ä½ç½®ç‰¹å¾
    location = nusc.get('log', scene['log_token'])['location']
    
    # 3. åœºæ™¯æè¿°ï¼ˆåŒ…å«å¤æ‚åº¦ä¿¡æ¯ï¼‰
    description = scene['description'].lower()
    
    # 4. ä¼°è®¡å¤æ‚åº¦ï¼ˆåŸºäºå…³é”®è¯ï¼‰
    complexity = 'simple'
    complex_keywords = ['turn', 'intersection', 'construction', 'crowded', 'heavy', 'stop']
    medium_keywords = ['lane', 'merge', 'traffic']
    
    if any(kw in description for kw in complex_keywords):
        complexity = 'complex'
    elif any(kw in description for kw in medium_keywords):
        complexity = 'medium'
    
    # 5. åœºæ™¯é•¿åº¦ï¼ˆå¸§æ•°ï¼‰
    frame_count = scene['nbr_samples']
    
    return {
        'name': scene['name'],
        'token': scene['token'],
        'location': location,
        'is_night': is_night,
        'complexity': complexity,
        'frame_count': frame_count,
        'description': scene['description']
    }


def smart_sample_scenes(nusc, n_samples=200, seed=42):
    """
    æ™ºèƒ½é‡‡æ ·nuScenesåœºæ™¯
    
    âš ï¸ é‡è¦è¯´æ˜ï¼š
    1. åªä» trainval (850åœºæ™¯) é‡‡æ ·ï¼Œtesté›†æ ‡æ³¨æœªå…¬å¼€æ— æ³•ä½¿ç”¨
    2. æœ¬é¡¹ç›®æ˜¯**çº¯æ¨ç†ï¼ˆé›¶è®­ç»ƒï¼‰**ï¼Œä¸è®­ç»ƒæ¨¡å‹å‚æ•°
    3. å› æ­¤ä¸å­˜åœ¨è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œtrainvalå…¨éƒ¨850åœºæ™¯éƒ½æ˜¯æœ‰æ•ˆè¯„ä¼°æ•°æ®
    4. ä¸éœ€è¦åŒºåˆ†train/valï¼ˆè¿™æ˜¯è®­ç»ƒåœºæ™¯æ‰éœ€è¦çš„ï¼‰
    
    nuScenesæ•°æ®é›†ç»“æ„ï¼š
    - trainval: 850 scenes (700 train + 150 valï¼Œæ ‡æ³¨å…¬å¼€) âœ… å¯ç”¨
    - test: 150 scenes (æ ‡æ³¨æœªå…¬å¼€ï¼Œä»…ç”¨äºåœ¨çº¿æ’è¡Œæ¦œ) âŒ ä¸å¯ç”¨
    - mini: 10 scenes (trainvalçš„å­é›†ï¼Œå·²å®Œæˆå®éªŒ)
    
    é‡‡æ ·ç›®æ ‡åˆ†å¸ƒï¼ˆ200ä¸ªåœºæ™¯ = trainvalçš„23.5%ï¼‰ï¼š
    - å¤æ‚åº¦: ç®€å•35%, ä¸­ç­‰47%, å¤æ‚18%
    - æ—¶é—´: ç™½å¤©70%, å¤œé—´30%
    - ä½ç½®: Boston 50%, Singapore 50%
    - é¿å…å·²çŸ¥å¼‚å¸¸åœºæ™¯ï¼ˆæç«¯æ›²ç‡ã€é™æ­¢è½¦è¾†ç­‰ï¼‰
    
    Args:
        nusc: NuSceneså¯¹è±¡ (version='v1.0-trainval')
        n_samples: é‡‡æ ·æ•°é‡ï¼ˆé»˜è®¤200ï¼‰
        seed: éšæœºç§å­ï¼ˆç”¨äºå¤ç°ï¼Œé»˜è®¤42ï¼‰
    
    Returns:
        list: é‡‡æ ·çš„åœºæ™¯åˆ—è¡¨ï¼ˆnuScenes sceneå¯¹è±¡ï¼‰
    """
    random.seed(seed)
    np.random.seed(seed)
    
    # å·²çŸ¥å¼‚å¸¸åœºæ™¯ï¼ˆéœ€è¦è¿‡æ»¤ï¼‰
    problematic_scenes = ['scene-0553', 'scene-0757', 'scene-1100']
    
    # åˆ†ææ‰€æœ‰åœºæ™¯ï¼ˆåŒæ—¶æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨ï¼‰
    print(f"ğŸ“Š åˆ†ænuScenesåœºæ™¯ç‰¹å¾...")
    all_scenes = []
    scenes_without_images = 0
    
    for scene in nusc.scene:
        if scene['name'] in problematic_scenes:
            continue
        
        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨ï¼ˆé‡è¦ï¼šç”¨æˆ·å¯èƒ½åªä¸‹è½½äº†éƒ¨åˆ†æ•°æ®ï¼‰
        if not check_scene_has_images(nusc, scene):
            scenes_without_images += 1
            continue
        
        features = analyze_scene_features(nusc, scene)
        all_scenes.append(features)
    
    print(f"âœ… å…±æœ‰ {len(all_scenes)} ä¸ªæœ‰æ•ˆåœºæ™¯ï¼ˆæœ‰å›¾ç‰‡æ•°æ®ï¼‰")
    if scenes_without_images > 0:
        print(f"âš ï¸  è·³è¿‡ {scenes_without_images} ä¸ªåœºæ™¯ï¼ˆå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼‰")
    
    # æŒ‰ç‰¹å¾åˆ†ç»„
    grouped = {
        'simple_day_boston': [],
        'simple_day_singapore': [],
        'simple_night_boston': [],
        'simple_night_singapore': [],
        'medium_day_boston': [],
        'medium_day_singapore': [],
        'medium_night_boston': [],
        'medium_night_singapore': [],
        'complex_day_boston': [],
        'complex_day_singapore': [],
        'complex_night_boston': [],
        'complex_night_singapore': [],
    }
    
    for scene_info in all_scenes:
        complexity = scene_info['complexity']
        time_of_day = 'night' if scene_info['is_night'] else 'day'
        location = 'boston' if 'boston' in scene_info['location'].lower() else 'singapore'
        
        key = f"{complexity}_{time_of_day}_{location}"
        if key in grouped:
            grouped[key].append(scene_info)
    
    # æ‰“å°åˆ†ç»„ç»Ÿè®¡
    print("\nğŸ“ˆ åœºæ™¯åˆ†å¸ƒç»Ÿè®¡:")
    for key, scenes in grouped.items():
        if scenes:
            print(f"  {key}: {len(scenes)} ä¸ªåœºæ™¯")
    
    # ç›®æ ‡åˆ†é…ï¼ˆæ ¹æ®n_samplesåŠ¨æ€è°ƒæ•´ï¼Œä¿æŒæ¯”ä¾‹ä¸€è‡´ï¼‰
    # åŸºç¡€æ¯”ä¾‹ï¼ˆ200åœºæ™¯ç‰ˆæœ¬ï¼‰
    base_distribution = {
        'simple_day_boston': 25/200,
        'simple_day_singapore': 25/200,
        'simple_night_boston': 10/200,
        'simple_night_singapore': 10/200,
        'medium_day_boston': 33/200,
        'medium_day_singapore': 33/200,
        'medium_night_boston': 14/200,
        'medium_night_singapore': 14/200,
        'complex_day_boston': 13/200,
        'complex_day_singapore': 13/200,
        'complex_night_boston': 5/200,
        'complex_night_singapore': 5/200,
    }
    
    # æ ¹æ®å®é™…n_samplesç¼©æ”¾
    target_distribution = {
        key: max(1, int(ratio * n_samples))  # è‡³å°‘1ä¸ª
        for key, ratio in base_distribution.items()
    }
    
    # å¾®è°ƒç¡®ä¿æ€»æ•°åŒ¹é…ï¼ˆç”±äºå››èˆäº”å…¥å¯èƒ½æœ‰å·®å¼‚ï¼‰
    total_allocated = sum(target_distribution.values())
    if total_allocated < n_samples:
        # è¡¥å……åˆ°medium_day_bostonï¼ˆæœ€å¤§ç±»åˆ«ï¼‰
        target_distribution['medium_day_boston'] += (n_samples - total_allocated)
    elif total_allocated > n_samples:
        # ä»medium_day_bostonå‡å°‘
        target_distribution['medium_day_boston'] -= (total_allocated - n_samples)
    
    # æ‰§è¡Œåˆ†å±‚é‡‡æ ·
    sampled_scenes = []
    remaining_pool = []  # æœªè¢«é‡‡æ ·çš„åœºæ™¯æ± 
    
    for key, target_count in target_distribution.items():
        available = grouped[key]
        
        if len(available) == 0:
            print(f"âš ï¸  {key}: æ²¡æœ‰å¯ç”¨åœºæ™¯ï¼Œè·³è¿‡")
            continue
        
        # å¦‚æœå¯ç”¨åœºæ™¯å°‘äºç›®æ ‡ï¼Œå…¨éƒ¨é‡‡æ ·
        if len(available) <= target_count:
            sampled = available
            print(f"âœ… {key}: é‡‡æ · {len(sampled)}/{target_count} (å…¨éƒ¨å¯ç”¨)")
        else:
            # éšæœºé‡‡æ ·
            sampled = random.sample(available, target_count)
            print(f"âœ… {key}: é‡‡æ · {len(sampled)}/{target_count}")
            # æœªè¢«é‡‡æ ·çš„åœºæ™¯åŠ å…¥å‰©ä½™æ± 
            remaining = [s for s in available if s not in sampled]
            remaining_pool.extend(remaining)
        
        sampled_scenes.extend(sampled)
    
    # å¦‚æœé‡‡æ ·æ•°ä¸è¶³ï¼Œä»å‰©ä½™æ± è¡¥å……
    shortage = n_samples - len(sampled_scenes)
    if shortage > 0 and remaining_pool:
        extra_samples = min(shortage, len(remaining_pool))
        extras = random.sample(remaining_pool, extra_samples)
        sampled_scenes.extend(extras)
        print(f"\nâ• ä»å‰©ä½™æ± è¡¥å…… {extra_samples} ä¸ªåœºæ™¯")
    
    print(f"\nğŸ¯ æ€»å…±é‡‡æ · {len(sampled_scenes)} ä¸ªåœºæ™¯")
    
    # è½¬æ¢å›nuScenes sceneå¯¹è±¡
    sampled_tokens = {s['token'] for s in sampled_scenes}
    result_scenes = [s for s in nusc.scene if s['token'] in sampled_tokens]
    
    # ä¿å­˜é‡‡æ ·ç»“æœï¼ˆç”¨äºå¤ç°ï¼‰
    sampling_log = {
        'seed': seed,
        'n_samples': len(sampled_scenes),
        'target_distribution': target_distribution,
        'sampled_scene_names': [s['name'] for s in sampled_scenes],
        'complexity_stats': {
            'simple': sum(1 for s in sampled_scenes if s['complexity'] == 'simple'),
            'medium': sum(1 for s in sampled_scenes if s['complexity'] == 'medium'),
            'complex': sum(1 for s in sampled_scenes if s['complexity'] == 'complex'),
        },
        'time_stats': {
            'day': sum(1 for s in sampled_scenes if not s['is_night']),
            'night': sum(1 for s in sampled_scenes if s['is_night']),
        },
        'location_stats': {
            'boston': sum(1 for s in sampled_scenes if 'boston' in s['location'].lower()),
            'singapore': sum(1 for s in sampled_scenes if 'singapore' in s['location'].lower()),
        }
    }
    
    # æ ¹æ®å®é™…é‡‡æ ·æ•°é‡ä¿å­˜æ–‡ä»¶
    filename = f'sampled_scenes_{len(sampled_scenes)}.json'
    with open(filename, 'w') as f:
        import json
        json.dump(sampling_log, f, indent=2)
    
    print(f"ğŸ“„ é‡‡æ ·æ—¥å¿—å·²ä¿å­˜åˆ°: {filename}")
    
    return result_scenes


def load_sampled_scenes(nusc, sampling_log_path='sampled_scenes_200.json'):
    """ä»é‡‡æ ·æ—¥å¿—åŠ è½½åœºæ™¯ï¼ˆç”¨äºå¤ç°ï¼‰"""
    import json
    
    with open(sampling_log_path, 'r') as f:
        log = json.load(f)
    
    scene_names = set(log['sampled_scene_names'])
    result_scenes = [s for s in nusc.scene if s['name'] in scene_names]
    
    print(f"âœ… ä»æ—¥å¿—åŠ è½½ {len(result_scenes)} ä¸ªåœºæ™¯")
    return result_scenes


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import sys
    import io
    # è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸ºUTF-8
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    
    # å‘½ä»¤è¡Œå‚æ•°
    dataroot = sys.argv[1] if len(sys.argv) > 1 else 'C:/Users/79120/OpenEMMA/openemma'
    n_samples = int(sys.argv[2]) if len(sys.argv) > 2 else 100  # é»˜è®¤100åœºæ™¯
    
    print(f"ğŸ”„ åŠ è½½nuScenes trainvalæ•°æ®é›†...")
    print(f"   æ•°æ®è·¯å¾„: {dataroot}")
    print(f"   ç‰ˆæœ¬: v1.0-trainval (700 train + 150 val = 850 scenes)")
    print(f"   âš ï¸  ä¸ä½¿ç”¨testé›†(150 scenes)ï¼Œä¿ç•™ç»™æœ€ç»ˆç«èµ›è¯„ä¼°")
    print(f"   ç›®æ ‡é‡‡æ ·: {n_samples} ä¸ªåœºæ™¯\n")
    
    nusc = NuScenes(version='v1.0-trainval', dataroot=dataroot, verbose=True)
    
    # æ™ºèƒ½é‡‡æ ·
    sampled = smart_sample_scenes(nusc, n_samples=n_samples, seed=42)
    
    print(f"\nâœ… é‡‡æ ·å®Œæˆï¼å…± {len(sampled)} ä¸ªåœºæ™¯")
    print(f"   é‡‡æ ·ç‡: {len(sampled)}/850 = {len(sampled)/850*100:.1f}%")
    print(f"   ç¬¬ä¸€ä¸ªåœºæ™¯: {sampled[0]['name']}")
    print(f"   æœ€åä¸€ä¸ªåœºæ™¯: {sampled[-1]['name']}")
    print(f"\nğŸ“„ é‡‡æ ·é…ç½®å·²ä¿å­˜åˆ°: sampled_scenes_{len(sampled)}.json")
    print(f"   å¯ç”¨äºå¤ç°å®éªŒï¼ˆseed=42ï¼‰")
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print(f"   python main.py --version v1.0-trainval --use-sampled-200 ...")

